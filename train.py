# 1. Import thÆ° viá»‡n
import os
import cv2
import numpy as np
import joblib
from skimage.feature import hog
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from tqdm import tqdm  # hiá»ƒn thá»‹ tiáº¿n trÃ¬nh

# 2. Download dataset tá»« gg drive
# dataset = https://drive.google.com/file/d/1kEd4pP0ArDlHfxQ6AxlaeMcMrGwjfz3d/view?usp=sharing
# Äáº£m báº£o thÆ° má»¥c "dataset" náº±m cÃ¹ng cáº¥p vá»›i tá»‡p train_model.py
dataset_path = "dataset/"

# 3. HOG (trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng)
def extract_hog_features(image_path, size=(128, 128)): #ThÃ´ng sá»‘ resize cá»§a áº£nh (cÃ ng cao cÃ ng chÃ­nh xÃ¡c)
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {image_path}")
    img = cv2.resize(img, size)
    features = hog(img,
                   orientations=9,
                   pixels_per_cell=(8, 8),
                   cells_per_block=(2, 2),
                   block_norm='L2-Hys',
                   visualize=False,
                   feature_vector=True)
    return features

# 4. Get dá»¯ liá»‡u (duyá»‡t sÃ¢u vÃ o tá»«ng folder con) vÃ  gÃ¡n nhÃ£n
def load_dataset(root_dir):
    X, y, labels = [], [], []
    label_map = {}
    label_id = 0

    class_dirs = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])

    for class_name in class_dirs:
        label_map[label_id] = class_name
        class_path = os.path.join(root_dir, class_name)
        files = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]

        print(f"ğŸ”¹ Lá»›p: {class_name} ({len(files)} áº£nh)")
        for file in tqdm(files, desc=f"  -> Xá»­ lÃ½ {class_name}", leave=False):
            file_path = os.path.join(class_path, file)
            try:
                feat = extract_hog_features(file_path)
                X.append(feat)
                y.append(label_id)
            except Exception as e:
                print(f"âš ï¸ Lá»—i vá»›i {file_path}: {e}")

        label_id += 1

    return np.array(X), np.array(y), label_map

# 5. Táº£i dá»¯ liá»‡u
print("\nğŸ“¥ Äang load dataset vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng HOG...")
X, y, label_map = load_dataset(dataset_path)

# 6. Chuáº©n hÃ³a Ä‘áº·c trÆ°ng
print("\nâš™ï¸  Äang chuáº©n hÃ³a dá»¯ liá»‡u...")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 7. Chia táº­p train/test
print("\nğŸ“Š Äang chia dá»¯ liá»‡u train/test...")
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# 8. Train SVM
print("\nğŸ§  Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh SVM...")
svm_model = SVC(kernel='linear', probability=True, C=1.0)
svm_model.fit(X_train, y_train)

# 9. LÆ°u model
print("\nğŸ’¾ Äang lÆ°u mÃ´ hÃ¬nh...")
joblib.dump((svm_model, scaler, label_map), "waste_classifier.pkl")
print("âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ o waste_classifier.pkl")

# 10. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
print("\nğŸ“ˆ Äang Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh...")
y_pred = svm_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
target_names = [label_map[i] for i in sorted(set(y))]
report = classification_report(y_test, y_pred, target_names=target_names)

print(f"\nğŸ¯ Äá»™ chÃ­nh xÃ¡c: {accuracy:.4f}")
print("\nğŸ“‹ BÃ¡o cÃ¡o phÃ¢n loáº¡i:\n")
print(report)